{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Imports"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"elapsed":9599,"status":"error","timestamp":1723830179090,"user":{"displayName":"Ali El Hakie","userId":"14299250198213300926"},"user_tz":-120},"id":"1B3HPSvoSH6M","outputId":"7533f997-404e-48f5-9111-811e91546559"},"outputs":[{"name":"stdout","output_type":"stream","text":["['Benign', 'Malignant']\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import tensorflow as tf\n","\n","\n","from keras import models, layers, optimizers, regularizers\n","from keras.models import Sequential\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from keras.applications import EfficientNetB6\n","import os\n","from pathlib import Path\n","from PIL import Image\n","print(os.listdir(\"train\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Extract and preprocess data:\n","Extract dataset for training and testing from folders: train and test   \n","  \n","Be careful! Run the only one of the three next cells in this section:\n","* First cell for sample centering  \n","* Second Cell for feature Centering  \n","* Third cell for using a center crop of (180,180), the model will also need input images of (180,180)  "]},{"cell_type":"markdown","metadata":{},"source":["Sample Centering"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"htgNsAoRSH6W","outputId":"e240f260-0b5e-402a-ee8c-fee67e091c57"},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 10098 images belonging to 2 classes.\n","Found 1781 images belonging to 2 classes.\n","Found 2000 images belonging to 2 classes.\n"]}],"source":["train_datagen = ImageDataGenerator(rotation_range=40,\n","                                   shear_range=20,\n","                                   horizontal_flip=True,\n","                                   vertical_flip=True,\n","                                   validation_split=0.15,\n","                                   samplewise_center=True,\n","                                   fill_mode='nearest',\n","                                   rescale=1.0/255.0)\n","\n","\n","test_datagen = ImageDataGenerator(samplewise_center=True,\n","                                  rescale=1.0/255.0)\n","\n","\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(224, 224), batch_size=16, class_mode='categorical', shuffle=True, subset='training')\n","\n","\n","val_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(224, 224), batch_size=8, class_mode='categorical', shuffle=True, subset='validation')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    \"test\", target_size=(224, 224), batch_size=8, class_mode='categorical')"]},{"cell_type":"markdown","metadata":{},"source":["Feature Centering"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_pil_image(img_path, height, width):\n","        with open(img_path, 'rb') as f:\n","            return np.array(Image.open(f).convert('RGB').resize((width, height)))\n","\n","def load_all_images(dataset_path, height, width, img_ext='jpg'):\n","    return np.array([read_pil_image(str(p), height, width) for p in \n","                                    Path(dataset_path).rglob(\"*.\"+img_ext)]) \n","\n","all_images = load_all_images('train/', 224, 224)\n","\n","train_datagen = ImageDataGenerator(rotation_range=40,\n","                                   shear_range=20,\n","                                   horizontal_flip=True,\n","                                   vertical_flip=True,\n","                                   validation_split=0.15,\n","                                   featurewise_center=True,\n","                                   fill_mode='nearest',\n","                                   rescale=1.0/255.0)\n","\n","\n","test_datagen = ImageDataGenerator(featurewise_center=True,\n","                                  rescale=1.0/255.0)\n","\n","train_datagen.fit(np.array([all_images.mean(axis=0)]))\n","test_datagen.fit(np.array([all_images.mean(axis=0)]))\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(224, 224), batch_size=16, class_mode='categorical', shuffle=True, subset='training')\n","\n","\n","val_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(224, 224), batch_size=8, class_mode='categorical', shuffle=True, subset='validation')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    \"test\", target_size=(224, 224), batch_size=8, class_mode='categorical')"]},{"cell_type":"markdown","metadata":{},"source":["Center crop of (180,180)  "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","train_datagen = ImageDataGenerator(preprocessing_function=tf.keras.layers.CenterCrop(180, 180),\n","                                   rotation_range=40,\n","                                   shear_range=20,\n","                                   horizontal_flip=True,\n","                                   vertical_flip=True,\n","                                   samplewise_center=True,\n","                                   fill_mode='nearest',\n","                                   validation_split=0.15,\n","                                   rescale=1.0/255.0)\n","\n","\n","test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.layers.CenterCrop(180, 180),\n","                                  samplewise_center=True,\n","                                  rescale=1.0/255.0)\n","\n","\n","train_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(180, 180), batch_size=16, class_mode='categorical', shuffle=True, subset='training')\n","\n","\n","val_generator = train_datagen.flow_from_directory(\n","    \"train\", target_size=(180, 180), batch_size=8, class_mode='categorical', shuffle=True, subset='validation')\n","\n","test_generator = test_datagen.flow_from_directory(\n","    \"test\", target_size=(180, 180), batch_size=8, class_mode='categorical', shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Model\n","Create model:  \n","\n"," * EfficientNetB6 base layer with top fully connected layer removed\n"," * a global average pooling 2D layer for feature extraction from EfficientNet\n"," * a dense layer with ReLu activation (because it is less susceptible to vanishing gradients)\n"," * a dense layer with softmax activation for classification (or sigmoid activation)   \n","   \n","__Use input shape according to the datagenerator chosen__\n","\n","If you want pretrained weights on ImageNet dataset use:\n","```\n","EfficientNetB6(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","```\n","\n","If you want a random initialisation:\n","```\n","EfficientNetB6(weights=None, include_top=False, input_shape=(224, 224, 3))\n","```\n","\n"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"BBDxPed6SH6h","outputId":"17b18a04-5ab9-4be9-a452-c20fe088f41f"},"outputs":[],"source":["# EfficientNetV2 Model\n","base = EfficientNetB6(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","model= Sequential()\n","model.add(base)\n","model.add(layers.GlobalAveragePooling2D())\n","model.add(layers.Dense(128, activation='relu'))\n","model.add(layers.Dense(2, activation='softmax')) #binary output layer\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics=['accuracy', 'AUC'])"]},{"cell_type":"markdown","metadata":{},"source":["Train and save model weights"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n"]},{"name":"stderr","output_type":"stream","text":["/home/alyelhakie/anaconda3/envs/tf/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n","WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n","I0000 00:00:1723908898.385156  133228 service.cc:146] XLA service 0x791874003ef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","I0000 00:00:1723908898.385173  133228 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1060, Compute Capability 6.1\n","2024-08-17 17:35:00.975779: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n","2024-08-17 17:35:10.333584: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n","E0000 00:00:1723908935.479379  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908935.628459  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908935.767142  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908936.208674  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908936.364250  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908936.974192  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908937.136144  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908938.005086  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908938.173545  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908938.980272  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908939.157467  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908939.329222  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908940.297685  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723908940.506922  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","I0000 00:00:1723908987.891698  133228 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m590/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m25s\u001b[0m 621ms/step - AUC: 0.9138 - accuracy: 0.8384 - loss: 0.3643"]},{"name":"stderr","output_type":"stream","text":["E0000 00:00:1723909382.159801  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909382.295400  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909382.434657  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909382.572645  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909382.933184  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909383.078548  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909383.710726  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","E0000 00:00:1723909383.879912  133228 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n","2024-08-17 17:43:55.001325: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion', 40 bytes spill stores, 40 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_1', 48 bytes spill stores, 48 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_3', 84 bytes spill stores, 84 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'input_add_reduce_fusion', 144 bytes spill stores, 144 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'input_multiply_reduce_fusion_1', 60 bytes spill stores, 120 bytes spill loads\n","ptxas warning : Registers are spilled to local memory in function 'input_reduce_fusion_6', 44 bytes spill stores, 44 bytes spill loads\n","\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m662s\u001b[0m 800ms/step - AUC: 0.9158 - accuracy: 0.8408 - loss: 0.3602 - val_AUC: 0.6934 - val_accuracy: 0.6115 - val_loss: 0.8481\n","Epoch 2/10\n","\u001b[1m  1/631\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6:19\u001b[0m 602ms/step - AUC: 0.9648 - accuracy: 0.8750 - loss: 0.2704"]},{"name":"stderr","output_type":"stream","text":["2024-08-17 17:44:53.009859: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","2024-08-17 17:44:53.011623: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\t [[IteratorGetNext/_2]]\n","/home/alyelhakie/anaconda3/envs/tf/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n","  self.gen.throw(typ, value, traceback)\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 16ms/step - AUC: 0.9648 - accuracy: 0.8750 - loss: 0.2704 - val_AUC: 0.9600 - val_accuracy: 0.8000 - val_loss: 0.3657\n","Epoch 3/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-08-17 17:45:02.953621: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\t [[IteratorGetNext/_2]]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m406s\u001b[0m 643ms/step - AUC: 0.9672 - accuracy: 0.9062 - loss: 0.2323 - val_AUC: 0.8978 - val_accuracy: 0.7945 - val_loss: 0.4419\n","Epoch 4/10\n","\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155us/step - AUC: 0.9727 - accuracy: 0.9375 - loss: 0.1962 - val_AUC: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.1188\n","Epoch 5/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-08-17 17:51:50.076811: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\t [[IteratorGetNext/_2]]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m405s\u001b[0m 639ms/step - AUC: 0.9785 - accuracy: 0.9244 - loss: 0.1870 - val_AUC: 0.9005 - val_accuracy: 0.8232 - val_loss: 0.4320\n","Epoch 6/10\n","\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 143us/step - AUC: 0.9727 - accuracy: 0.9375 - loss: 0.2165 - val_AUC: 0.7200 - val_accuracy: 0.8000 - val_loss: 0.5448\n","Epoch 7/10\n","\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m433s\u001b[0m 685ms/step - AUC: 0.9807 - accuracy: 0.9281 - loss: 0.1776 - val_AUC: 0.9088 - val_accuracy: 0.8238 - val_loss: 0.4494\n","Epoch 8/10\n","\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 144us/step - AUC: 0.9727 - accuracy: 0.9375 - loss: 0.2096 - val_AUC: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0368\n","Epoch 9/10\n"]},{"name":"stderr","output_type":"stream","text":["2024-08-17 18:05:49.520796: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n","\t [[{{node IteratorGetNext}}]]\n","\t [[IteratorGetNext/_2]]\n"]},{"name":"stdout","output_type":"stream","text":["\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m447s\u001b[0m 707ms/step - AUC: 0.9865 - accuracy: 0.9459 - loss: 0.1465 - val_AUC: 0.9148 - val_accuracy: 0.8350 - val_loss: 0.4420\n","Epoch 10/10\n","\u001b[1m631/631\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 186us/step - AUC: 0.9961 - accuracy: 0.9375 - loss: 0.1235 - val_AUC: 1.0000 - val_accuracy: 1.0000 - val_loss: 0.0157\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}],"source":["history = model.fit(train_generator, epochs=10, steps_per_epoch=train_generator.n//train_generator.batch_size,\n","                    validation_data=val_generator, validation_steps=val_generator.n//val_generator.batch_size)\n","\n","model.save(\"models/efficient_net_b6_samplewise_10.h5\")"]},{"cell_type":"markdown","metadata":{},"source":["Evaluate Model"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 93ms/step - AUC: 0.9681 - accuracy: 0.9053 - loss: 0.2303\n"]}],"source":["test_AUC, test_acc, test_loss = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["To generate list of predictions from test set images"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 48ms/step\n"]}],"source":["test_predictions = model.predict(test_generator)\n"]},{"cell_type":"markdown","metadata":{},"source":["Test Models\n","\n","Be careful to use same activation function for final layer (softmax or sigmoid depending on ckpt)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["ckpt ='efficient_net_b6_samplewise_10.h5'\n","\n","# # Use if using featurewise centering\n","# test_datagen = ImageDataGenerator(featurewise_center=True, rescale=1.0/255.0)\n","# test_datagen.fit(np.array([all_images.mean(axis=0)]))\n","# test_generator = test_datagen.flow_from_directory(\"test\", target_size=(224, 224), batch_size=8, class_mode='categorical')\n","\n","\n","\n","# #Use if using samplewise centering\n","# test_datagen = ImageDataGenerator(samplewise_center=True, rescale=1.0/255.0)\n","# test_generator = test_datagen.flow_from_directory(\"test\", target_size=(224, 224), batch_size=8, class_mode='categorical')\n","\n","#Use if using samplewise centering and the (180,180) center crop model\n","test_datagen = ImageDataGenerator(preprocessing_function=tf.keras.layers.CenterCrop(180, 180), samplewise_center=True, rescale=1.0/255.0)\n","test_generator = test_datagen.flow_from_directory(\"test\", target_size=(180, 180), batch_size=8, class_mode='categorical', shuffle=True)\n","   \n","   \n","test_model = tf.keras.models.load_model(filepath='models/' + ckpt)\n","\n","print(f\"Model:{ckpt}\")\n","test_model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"interpreter":{"hash":"02d0bbccf2a704642cb7f96e46f89c40b318e3edf8fed0bd36cb762691a6d5c6"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
